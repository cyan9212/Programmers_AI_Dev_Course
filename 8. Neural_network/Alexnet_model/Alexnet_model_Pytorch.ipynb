{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Alexnet_model_Pytorch.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "OVgbX2KrCTSy"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "from typing import Any"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "__all__ = ['Alexnet', 'alexnet']\n",
        "\n",
        "model_urls = {\n",
        "    'alexnet': 'https://download.pytorch.org/models/alexnet-owt-4df8aa71.pth',\n",
        "}"
      ],
      "metadata": {
        "id": "CHWKMwbYC8NW"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class AlexNet(nn.Module):\n",
        "  def __init__(self, num_classes: int=1000) -> None:\n",
        "    super(AlexNet, self).__init__()\n",
        "    self.features = nn.Sequential(\n",
        "        # Conv1\n",
        "        # Input channel:3, output channel:64, kernel size: 11, stride: 4, padding: 2\n",
        "        nn.Conv2d(3, 64, kernel_size=11, stride=4, padding=2),\n",
        "        nn.ReLU(inplace=True), # inplace 연산은 결과값을 새로운 변수에 값을 저장하는 대신 기존의 데이터를 대체하는 것을 의미\n",
        "        # Max Pool1\n",
        "        nn.MaxPool2d(kernel_size=3, stride=2),\n",
        "\n",
        "        # Conv2\n",
        "        nn.Conv2d(64, 192, kernel_size=5, padding=2),\n",
        "        nn.ReLU(inplace=True),\n",
        "        # Max Pool2\n",
        "        nn.MaxPool2d(kernel_size=3, stride=2),\n",
        "\n",
        "        # Conv3\n",
        "        nn.Conv2d(192, 384, kernel_size=3, padding=1),\n",
        "        nn.ReLU(inplace=True),\n",
        "        \n",
        "        # Conv4\n",
        "        nn.Conv2d(384, 256, kernel_size=3, padding=1),\n",
        "        nn.ReLU(inplace=True),\n",
        "\n",
        "        # Conv5\n",
        "        nn.Conv2d(256, 256, kernel_size=3, padding=1),\n",
        "        nn.ReLU(inplace=True),\n",
        "        # Max Pool3\n",
        "        nn.MaxPool2d(kernel_size=3, stride=2),\n",
        "    ) \n",
        "    self.avgpool = nn.AdaptiveAveragePool2d((6, 6))\n",
        "    self.classifier = nn.Sequential(\n",
        "      # 드롭아웃\n",
        "      nn.Dropout(),\n",
        "      nn.Linear(256 * 6 * 6, 4096),\n",
        "      nn.ReLU(inplace=True),\n",
        "\n",
        "      nn.Dropout(),\n",
        "      nn.Linear(4096, 4096),\n",
        "      nn.ReLU(inplace=True),\n",
        "\n",
        "      nn.Linear(4096, num_classes),\n",
        "  )\n",
        "  def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
        "    # 특징 추출 부분\n",
        "    x = self.features(x)\n",
        "\n",
        "    x = self.avgpool(x)\n",
        "    # output shape: (batch size * 256(channel), 6, 6)\n",
        "    # Flatten\n",
        "    x = torch.flatten(x, 1)\n",
        "    # output shape (batch size, 256 * 6 * 6)\n",
        "    # 분류 \n",
        "    x = self.classifier(x)\n",
        "    return x"
      ],
      "metadata": {
        "id": "9jU0kj8qCoAI"
      },
      "execution_count": 15,
      "outputs": []
    }
  ]
}